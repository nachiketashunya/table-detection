{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n",
      "08/13 16:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1634574429\n",
      "    GPU 0: NVIDIA A30\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (GCC) 12.3.0\n",
      "    PyTorch: 2.3.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.18.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1634574429\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/13 16:42:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "checkpoint_config = dict(create_symlink=False, interval=1)\n",
      "classes = 'Table'\n",
      "data_root = '/scratch/m23csa016/tabdet_data/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        extra=dict(\n",
      "            stage1=dict(\n",
      "                block='BOTTLENECK',\n",
      "                num_blocks=(4, ),\n",
      "                num_branches=1,\n",
      "                num_channels=(64, ),\n",
      "                num_modules=1),\n",
      "            stage2=dict(\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_branches=2,\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                ),\n",
      "                num_modules=1),\n",
      "            stage3=dict(\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_branches=3,\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                ),\n",
      "                num_modules=4),\n",
      "            stage4=dict(\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_branches=4,\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                    256,\n",
      "                ),\n",
      "                num_modules=3)),\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://msra/hrnetv2_w32', type='Pretrained'),\n",
      "        type='HRNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            32,\n",
      "            64,\n",
      "            128,\n",
      "            256,\n",
      "        ], out_channels=256, type='HRFPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=1,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=1,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=1,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=2, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        mask_head=dict(\n",
      "            conv_out_channels=256,\n",
      "            in_channels=256,\n",
      "            loss_mask=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "            num_classes=1,\n",
      "            num_convs=4,\n",
      "            type='FCNMaskHead'),\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=2, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='CascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_num=1000,\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_across_levels=False,\n",
      "            nms_post=1000,\n",
      "            nms_pre=1000,\n",
      "            nms_thr=0.7)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_num=2000,\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_across_levels=False,\n",
      "            nms_post=2000,\n",
      "            nms_pre=2000,\n",
      "            nms_thr=0.7),\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ]),\n",
      "    type='CascadeRCNN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(lr=0.002, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=1000,\n",
      "        start_factor=0.3333333333333333,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            16,\n",
      "            19,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/scratch/m23csa016/tabdet_data/Dilated'),\n",
      "        data_root='/scratch/m23csa016/tabdet_data/',\n",
      "        metainfo=dict(classes='Table'),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=2)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='/scratch/m23csa016/tabdet_data/Annotations/train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/scratch/m23csa016/tabdet_data/Dilated'),\n",
      "        data_root='/scratch/m23csa016/tabdet_data/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(classes='Table'),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/scratch/m23csa016/tabdet_data/Dilated'),\n",
      "        data_root='/scratch/m23csa016/tabdet_data/',\n",
      "        metainfo=dict(classes='Table'),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/new_config'\n",
      "\n",
      "08/13 16:42:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/13 16:42:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/csehome/m23csa016/MTP/mmdetection/tools/train.py\", line 122, in <module>\n",
      "    main()\n",
      "  File \"/csehome/m23csa016/MTP/mmdetection/tools/train.py\", line 111, in main\n",
      "    runner = Runner.from_cfg(cfg)\n",
      "  File \"/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/mmengine/runner/runner.py\", line 462, in from_cfg\n",
      "    runner = cls(\n",
      "  File \"/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/mmengine/runner/runner.py\", line 448, in __init__\n",
      "    self.dump_config()\n",
      "  File \"/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/mmengine/dist/utils.py\", line 427, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/mmengine/runner/runner.py\", line 2284, in dump_config\n",
      "    self.cfg.dump(osp.join(self.work_dir, filename))\n",
      "  File \"/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/mmengine/config/config.py\", line 1574, in dump\n",
      "    with open(file, 'w', encoding='utf-8') as f:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/train.py CascadeTabNet/Config/new_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/MTP\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19 14:57:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1223103740\n",
      "    GPU 0: NVIDIA A30\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.2, V12.2.91\n",
      "    GCC: gcc (GCC) 12.3.0\n",
      "    PyTorch: 2.3.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.18.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1223103740\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "08/19 14:57:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "classes = 'Table'\n",
      "data_root = '/scratch/m23csa016/tabdet_data/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=True,\n",
      "        interval=30,\n",
      "        out_dir='/csehome/m23csa016/MTP/CascadeTabNet/Checkpoints/Orig_Image',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = 'CascadeTabNet/Checkpoints/Original/new_config/epoch_100.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        extra=dict(\n",
      "            stage1=dict(\n",
      "                block='BOTTLENECK',\n",
      "                num_blocks=(4, ),\n",
      "                num_branches=1,\n",
      "                num_channels=(64, ),\n",
      "                num_modules=1),\n",
      "            stage2=dict(\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_branches=2,\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                ),\n",
      "                num_modules=1),\n",
      "            stage3=dict(\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_branches=3,\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                ),\n",
      "                num_modules=4),\n",
      "            stage4=dict(\n",
      "                block='BASIC',\n",
      "                num_blocks=(\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                    4,\n",
      "                ),\n",
      "                num_branches=4,\n",
      "                num_channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    128,\n",
      "                    256,\n",
      "                ),\n",
      "                num_modules=3)),\n",
      "        init_cfg=dict(\n",
      "            checkpoint='open-mmlab://msra/hrnetv2_w32', type='Pretrained'),\n",
      "        type='HRNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            32,\n",
      "            64,\n",
      "            128,\n",
      "            256,\n",
      "        ], out_channels=256, type='HRFPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=1,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=1,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=1,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=2, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        mask_head=dict(\n",
      "            conv_out_channels=256,\n",
      "            in_channels=256,\n",
      "            loss_mask=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "            num_classes=1,\n",
      "            num_convs=4,\n",
      "            type='FCNMaskHead'),\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=2, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='CascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_num=1000,\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_across_levels=False,\n",
      "            nms_post=1000,\n",
      "            nms_pre=1000,\n",
      "            nms_thr=0.7)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_num=2000,\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_across_levels=False,\n",
      "            nms_post=2000,\n",
      "            nms_pre=2000,\n",
      "            nms_thr=0.7),\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ]),\n",
      "    type='CascadeRCNN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(lr=0.002, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=1000,\n",
      "        start_factor=0.3333333333333333,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=28,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            16,\n",
      "            19,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/scratch/m23csa016/tabdet_data/Orig_Image'),\n",
      "        data_root='/scratch/m23csa016/tabdet_data/',\n",
      "        metainfo=dict(classes='Table'),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='/scratch/m23csa016/tabdet_data/Annotations/train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/scratch/m23csa016/tabdet_data/Orig_Image'),\n",
      "        data_root='/scratch/m23csa016/tabdet_data/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(classes='Table'),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='/scratch/m23csa016/tabdet_data/Orig_Image'),\n",
      "        data_root='/scratch/m23csa016/tabdet_data/',\n",
      "        metainfo=dict(classes='Table'),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='/scratch/m23csa016/tabdet_data/Annotations/test.json',\n",
      "    backend_args=None,\n",
      "    classwise=True,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'CascadeTabNet/evaluations/Original/'\n",
      "\n",
      "08/19 14:57:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "08/19 14:57:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "08/19 14:57:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Table is not a meta file, simply parsed as meta information\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: CascadeTabNet/Checkpoints/Original/new_config/epoch_100.pth\n",
      "08/19 14:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from CascadeTabNet/Checkpoints/Original/new_config/epoch_100.pth\n",
      "/csehome/m23csa016/MTP/mmdetection/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  mask_preds = bboxes.new_tensor(mask_preds)\n",
      "08/19 14:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 50/387]    eta: 0:00:37  time: 0.1124  data_time: 0.0107  memory: 766  \n",
      "08/19 14:57:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/387]    eta: 0:00:27  time: 0.0772  data_time: 0.0009  memory: 789  \n",
      "08/19 14:57:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [150/387]    eta: 0:00:20  time: 0.0745  data_time: 0.0009  memory: 789  \n",
      "08/19 14:57:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/387]    eta: 0:00:15  time: 0.0713  data_time: 0.0009  memory: 789  \n",
      "08/19 14:57:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [250/387]    eta: 0:00:11  time: 0.0739  data_time: 0.0009  memory: 789  \n",
      "08/19 14:57:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [300/387]    eta: 0:00:06  time: 0.0733  data_time: 0.0009  memory: 827  \n",
      "08/19 14:57:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [350/387]    eta: 0:00:02  time: 0.0737  data_time: 0.0009  memory: 774  \n",
      "08/19 14:57:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.906\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.941\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.918\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.505\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.909\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.925\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.925\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.925\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.927\n",
      "08/19 14:57:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+-------+-------+-------+\n",
      "| Table    | 0.906 | 0.941  | 0.918  | nan   | 0.505 | 0.909 |\n",
      "+----------+-------+--------+--------+-------+-------+-------+\n",
      "08/19 14:57:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.906 0.941 0.918 -1.000 0.505 0.909\n",
      "08/19 14:57:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.906\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.941\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.918\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.505\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.907\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.924\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.924\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.924\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.925\n",
      "08/19 14:57:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+----------+-------+--------+--------+-------+-------+-------+\n",
      "| category | mAP   | mAP_50 | mAP_75 | mAP_s | mAP_m | mAP_l |\n",
      "+----------+-------+--------+--------+-------+-------+-------+\n",
      "| Table    | 0.906 | 0.941  | 0.918  | nan   | 0.505 | 0.907 |\n",
      "+----------+-------+--------+--------+-------+-------+-------+\n",
      "08/19 14:57:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.906 0.941 0.918 -1.000 0.505 0.907\n",
      "08/19 14:57:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [387/387]    coco/Table_precision: 0.9060  coco/bbox_mAP: 0.9060  coco/bbox_mAP_50: 0.9410  coco/bbox_mAP_75: 0.9180  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.5050  coco/bbox_mAP_l: 0.9090  coco/segm_mAP: 0.9060  coco/segm_mAP_50: 0.9410  coco/segm_mAP_75: 0.9180  coco/segm_mAP_s: -1.0000  coco/segm_mAP_m: 0.5050  coco/segm_mAP_l: 0.9070  data_time: 0.0022  time: 0.0788\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/test.py CascadeTabNet/Config/new_config.py CascadeTabNet/Checkpoints/Original/new_config/epoch_100.pth --work-dir CascadeTabNet/evaluations/Original/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/MTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd MTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "# Initialize the DetInferencer\n",
    "inferencer = DetInferencer(model='CascadeTabNet/Config/new_config.py', weights='/csehome/m23csa016/MTP/work_dirs/new_config/epoch_64.pth')\n",
    "\n",
    "# Perform inference\n",
    "bbox = inferencer('/csehome/m23csa016/largepreview.png', out_dir='CascadeTabNet/testres', no_save_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/MTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/MTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "# Paths\n",
    "# Specify the path to model config and checkpoint file\n",
    "data_root = \"/scratch/m23csa016/tabdet_data\"\n",
    "config_path = 'CascadeTabNet/Config'\n",
    "checkpoint_path = 'CascadeTabNet/Checkpoints'\n",
    "\n",
    "image_folder = os.path.join(data_root, \"Orig_Image\")  # Single folder for all images\n",
    "test_annotation_file = os.path.join(data_root, \"Annotations/test.json\")  # Test annotation file path\n",
    "output_dir = 'CascadeTabNet/testres'\n",
    "\n",
    "for p in [40]:\n",
    "    config_file = os.path.join(config_path, f\"config_{p}.py\")\n",
    "    checkpoint_file = os.path.join(checkpoint_path, f\"Data_{p}/train_{p}/epoch_200.pth\")\n",
    "\n",
    "    out_dir = os.path.join(output_dir, f'data_{p}/end2end')\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    pred_dir = os.path.join(out_dir, \"preds\")\n",
    "    os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize the DetInferencer\n",
    "    inferencer = DetInferencer(model=config_file, weights=checkpoint_file)\n",
    "    # Load test annotations\n",
    "    with open(test_annotation_file) as f:\n",
    "        test_annotations = json.load(f)\n",
    "\n",
    "    # Get test image filenames\n",
    "    test_image_filenames = [img['file_name'] for img in test_annotations['images']]\n",
    "\n",
    "    # Run inference and save results\n",
    "    for img_filename in test_image_filenames:\n",
    "        img_path = os.path.join(image_folder, img_filename)\n",
    "        \n",
    "        # Perform inference\n",
    "        result = inferencer(img_path, out_dir=out_dir)\n",
    "\n",
    "        # Process the result to the desired format\n",
    "        output = []\n",
    "        # Extracting labels, scores, and bboxes\n",
    "        if len(result['predictions'][0]['labels']) != 0:\n",
    "            label = result['predictions'][0]['labels'][0]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        if len(result['predictions'][0]['scores']) != 0:\n",
    "            score = result['predictions'][0]['scores'][0]           \n",
    "        else:\n",
    "            score = 0\n",
    "\n",
    "        if len(result['predictions'][0]['bboxes']) != 0:\n",
    "            bbox = result['predictions'][0]['bboxes'][0]\n",
    "        else:\n",
    "            bbox = [-1, -1, -1, -1]\n",
    "\n",
    "        x_min, y_min, x_max, y_max = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "\n",
    "        output.append(f\"{label} {score:.4f} {x_min:.2f} {y_min:.2f} {x_max:.2f} {y_max:.2f}\")\n",
    "\n",
    "        # Keep track of correctly detected tables\n",
    "        if score < 0.95:\n",
    "            with open(f\"{out_dir}/undetected.txt\", 'a+') as f:\n",
    "                f.write(f\"-1 {score:.4f} {img_filename}\\n\")\n",
    "        \n",
    "        else:\n",
    "            with open(f\"{out_dir}/detected.txt\", 'a+') as f:\n",
    "                f.write(f\"0 {score:.4f} {img_filename}\\n\")\n",
    "        \n",
    "        # Save the results to a file\n",
    "        with open(f\"{pred_dir}/{img_filename}.txt\", 'w') as f:\n",
    "            f.write(\"\\n\".join(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/MTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csehome/m23csa016/.conda/envs/pyten/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot curve of CascadeTabNet/work_dirs/new_config/20240816_192104/vis_data/20240816_192104.json, metric is s0.acc\n",
      "plot curve of CascadeTabNet/work_dirs/new_config/20240816_192104/vis_data/20240816_192104.json, metric is s1.acc\n",
      "plot curve of CascadeTabNet/work_dirs/new_config/20240816_192104/vis_data/20240816_192104.json, metric is s2.acc\n",
      "save curve to: CascadeTabNet/evaluations/Dilated/plots/accuracy.pdf\n"
     ]
    }
   ],
   "source": [
    "!python mmdetection/tools/analysis_tools/analyze_logs.py plot_curve CascadeTabNet/work_dirs/new_config/20240816_192104/vis_data/20240816_192104.json --keys s0.acc s1.acc s2.acc --legend s0.acc s1.acc s2.acc --out CascadeTabNet/evaluations/Dilated/plots/accuracy.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_prefix_from_filenames(directory, prefix):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(prefix):\n",
    "            new_filename = filename[len(prefix):]\n",
    "            old_file_path = os.path.join(directory, filename)\n",
    "            new_file_path = os.path.join(directory, new_filename)\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f'Renamed: {old_file_path} -> {new_file_path}')\n",
    "\n",
    "# Example usage\n",
    "directory = '/scratch/m23csa016/tabdet_data/Smudged'\n",
    "prefix = 'Smudge_'\n",
    "remove_prefix_from_filenames(directory, prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset JSON file created: train_10.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "def create_subset_json(input_json_path, output_json_path, subset_percentage):\n",
    "    # Load the original JSON file\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Calculate the number of images and annotations to include in the subset\n",
    "    total_images = len(data['images'])\n",
    "    subset_size = int(total_images * subset_percentage / 100)\n",
    "    \n",
    "    # Randomly select a subset of images\n",
    "    subset_images = random.sample(data['images'], subset_size)\n",
    "    subset_image_ids = set([image['id'] for image in subset_images])\n",
    "    \n",
    "    # Filter annotations that correspond to the selected images\n",
    "    subset_annotations = [anno for anno in data['annotations'] if anno['image_id'] in subset_image_ids]\n",
    "    \n",
    "    # Create the subset JSON structure\n",
    "    subset_data = {\n",
    "        'images': subset_images,\n",
    "        'annotations': subset_annotations,\n",
    "        'categories': data['categories']\n",
    "    }\n",
    "    \n",
    "    # Save the subset JSON to a new file\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(subset_data, f, indent=4)\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# create_subset('train.json', 'train_15.json', 15)\n",
    "# create_subset('train.json', 'train_20.json', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/scratch/m23csa016/tabdet_data/Annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [10, 15, 20, 25, 30, 40]\n",
    "\n",
    "for per in percentages:\n",
    "    create_subset_json(os.path.join(data_root, 'train.json'), os.path.join(data_root, f'train_{per}.json'), per)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def update_config(config_path, percentage, subset_json_path, checkpoint_dir):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config_data = file.read()\n",
    "\n",
    "    config_data = config_data.replace(\"Annotations/train.json\", f'Annotations/train_{percentage}.json')\n",
    "    \n",
    "    # Update the checkpoint file path\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'Data_{percentage}')\n",
    "    os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "    config_data = config_data.replace(\"out_dir='/csehome/m23csa016/MTP/CascadeTabNet/Checkpoints/Orig_Image'\", f\"out_dir='{checkpoint_path}'\")\n",
    "    \n",
    "    # Write the updated config to a new file\n",
    "    new_config_path = os.path.join(\"/csehome/m23csa016/MTP/CascadeTabNet/Config\", f'config_{percentage}.py')\n",
    "    with open(new_config_path, 'w') as file:\n",
    "        file.write(config_data)\n",
    "    \n",
    "    return new_config_path\n",
    "\n",
    "config_path = 'CascadeTabNet/Config/new_config.py'\n",
    "subset_json_path = '/scratch/m23csa016/tabdet_data/Annotations'\n",
    "checkpoint_dir = '/csehome/m23csa016/MTP/CascadeTabNet/Checkpoints'\n",
    "\n",
    "for percentage in [10, 15, 20, 25, 30, 40]:\n",
    "    new_config_path = update_config(config_path, percentage, subset_json_path, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/csehome/m23csa016/MTP/CascadeTabNet/work_dirs\"\n",
    "\n",
    "for p in [10, 15, 20, 25, 30, 40]:\n",
    "    os.makedirs(os.path.join(work_dir, f'train_{p}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['98_214.xml', '97_95.xml', '98_141.xml', '9_81.xml', '98_143.xml']\n"
     ]
    }
   ],
   "source": [
    "xmlfiles = os.listdir(\"/scratch/m23csa016/tabdet_data/Orig_Annotations\")\n",
    "print(xmlfiles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Shuffle the list to randomize the order\n",
    "random.shuffle(xmlfiles)\n",
    "\n",
    "# Calculate the split point for 30-70 ratio\n",
    "split_index = int(0.7 * len(xmlfiles))\n",
    "\n",
    "# Split into train and test sets\n",
    "test_files = xmlfiles[:split_index]  # 70% for testing\n",
    "train_files = xmlfiles[split_index:]   # 30% for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name: 97_207.xml and image_id 1\n",
      "File Name: 10_261.xml and image_id 2\n",
      "File Name: 10.1.1.100.2013_22.xml and image_id 3\n",
      "File Name: 10.1.1.6.2249_15.xml and image_id 4\n",
      "File Name: 10.1.1.6.2352_5.xml and image_id 5\n",
      "File Name: 10.1.1.1.2094_3.xml and image_id 6\n",
      "File Name: cTDaR_t10509.xml and image_id 7\n",
      "File Name: 9561_044.xml and image_id 8\n",
      "File Name: 5373_008.xml and image_id 9\n",
      "File Name: 9569_024.xml and image_id 10\n",
      "File Name: 77_133.xml and image_id 11\n",
      "File Name: 0212_175.xml and image_id 12\n",
      "File Name: 9571_020.xml and image_id 13\n",
      "File Name: cTDaR_t10466.xml and image_id 14\n",
      "File Name: cTDaR_t10246.xml and image_id 15\n",
      "File Name: 9508_056.xml and image_id 16\n",
      "File Name: 44_292.xml and image_id 17\n",
      "File Name: 10.1.1.160.552_20.xml and image_id 18\n",
      "File Name: 10.1.1.1.2100_9.xml and image_id 19\n",
      "File Name: 43_106.xml and image_id 20\n",
      "File Name: 44_287.xml and image_id 21\n",
      "File Name: cTDaR_t10593.xml and image_id 22\n",
      "File Name: 39_25.xml and image_id 23\n",
      "File Name: 10.1.1.190.1811_2.xml and image_id 24\n",
      "File Name: 5001_032.xml and image_id 25\n",
      "File Name: 1495_021.xml and image_id 26\n",
      "File Name: 20_58.xml and image_id 27\n",
      "File Name: cTDaR_t10456.xml and image_id 28\n",
      "File Name: cTDaR_t10483.xml and image_id 29\n",
      "File Name: 26_25.xml and image_id 30\n",
      "File Name: 5017_041.xml and image_id 31\n",
      "File Name: cTDaR_t10247.xml and image_id 32\n",
      "File Name: 9510_031.xml and image_id 33\n",
      "File Name: 10.1.1.7.2119_22.xml and image_id 34\n",
      "File Name: 16_114.xml and image_id 35\n",
      "File Name: 0147_090.xml and image_id 36\n",
      "File Name: cTDaR_t10087.xml and image_id 37\n",
      "File Name: 0154_080.xml and image_id 38\n",
      "File Name: 77_141.xml and image_id 39\n",
      "File Name: 77_289.xml and image_id 40\n",
      "File Name: cTDaR_t10130.xml and image_id 41\n",
      "File Name: cTDaR_t10286.xml and image_id 42\n",
      "File Name: cTDaR_t10449.xml and image_id 43\n",
      "File Name: 10.1.1.34.7043_189.xml and image_id 44\n",
      "File Name: cTDaR_t10369.xml and image_id 45\n",
      "File Name: cTDaR_t10595.xml and image_id 46\n",
      "File Name: 10.1.1.193.1816_3.xml and image_id 47\n",
      "File Name: 10.1.1.172.1002_32.xml and image_id 48\n",
      "File Name: cTDaR_t10226.xml and image_id 49\n",
      "File Name: 93_212.xml and image_id 50\n",
      "File Name: 10.1.1.6.2297_10.xml and image_id 51\n",
      "File Name: 10.1.1.160.675_6.xml and image_id 52\n",
      "File Name: 10.1.1.12.1775_12.xml and image_id 53\n",
      "File Name: 10.1.1.1.2087_15.xml and image_id 54\n",
      "File Name: 10.1.1.160.510_36.xml and image_id 55\n",
      "File Name: 10.1.1.6.2234_6.xml and image_id 56\n",
      "File Name: cTDaR_t10390.xml and image_id 57\n",
      "File Name: 10.1.1.8.2198_13.xml and image_id 58\n",
      "File Name: cTDaR_t10043.xml and image_id 59\n",
      "File Name: 5117_023.xml and image_id 60\n",
      "File Name: 86_285.xml and image_id 61\n",
      "File Name: 10.1.1.160.546_34.xml and image_id 62\n",
      "File Name: 79_194.xml and image_id 63\n",
      "File Name: 48_52.xml and image_id 64\n",
      "File Name: cTDaR_t10568.xml and image_id 65\n",
      "File Name: cTDaR_t10350.xml and image_id 66\n",
      "File Name: 87_11.xml and image_id 67\n",
      "File Name: 10.1.1.36.5934_16.xml and image_id 68\n",
      "File Name: cTDaR_t10521.xml and image_id 69\n",
      "File Name: 10.1.1.6.2280_13.xml and image_id 70\n",
      "File Name: 44_96.xml and image_id 71\n",
      "File Name: 10.1.1.7.2123_3.xml and image_id 72\n",
      "File Name: 10.1.1.1.2072_4.xml and image_id 73\n",
      "File Name: cTDaR_t10306.xml and image_id 74\n",
      "File Name: 10.1.1.6.2314_6.xml and image_id 75\n",
      "File Name: 1176_003.xml and image_id 76\n",
      "File Name: cTDaR_t10308.xml and image_id 77\n",
      "File Name: cTDaR_t10047.xml and image_id 78\n",
      "File Name: 57_226.xml and image_id 79\n",
      "File Name: cTDaR_t10367.xml and image_id 80\n",
      "File Name: 0626_005.xml and image_id 81\n",
      "File Name: cTDaR_t10464.xml and image_id 82\n",
      "File Name: 33_110.xml and image_id 83\n",
      "File Name: 10.1.1.1.2075_6.xml and image_id 84\n",
      "File Name: 10.1.1.100.302_12.xml and image_id 85\n",
      "File Name: 9504_025.xml and image_id 86\n",
      "File Name: cTDaR_t10041.xml and image_id 87\n",
      "File Name: 77_130.xml and image_id 88\n",
      "File Name: cTDaR_t10340.xml and image_id 89\n",
      "File Name: cTDaR_t10412.xml and image_id 90\n",
      "File Name: cTDaR_t10404.xml and image_id 91\n",
      "File Name: 3_107.xml and image_id 92\n",
      "File Name: cTDaR_t10419.xml and image_id 93\n",
      "File Name: 9527_024.xml and image_id 94\n",
      "File Name: 57_50.xml and image_id 95\n",
      "File Name: 28_319.xml and image_id 96\n",
      "File Name: 10.1.1.190.1808_5.xml and image_id 97\n",
      "File Name: 5625_007.xml and image_id 98\n",
      "File Name: 75_51.xml and image_id 99\n",
      "File Name: 10.1.1.160.699_75.xml and image_id 100\n",
      "File Name: 10.1.1.160.623_7.xml and image_id 101\n",
      "File Name: 5099_068.xml and image_id 102\n",
      "File Name: cTDaR_t10364.xml and image_id 103\n",
      "File Name: 64_17.xml and image_id 104\n",
      "File Name: 1662_085.xml and image_id 105\n",
      "File Name: 9548_031.xml and image_id 106\n",
      "File Name: cTDaR_t10140.xml and image_id 107\n",
      "File Name: 1552_032.xml and image_id 108\n",
      "File Name: 77_292.xml and image_id 109\n",
      "File Name: 43_20.xml and image_id 110\n",
      "File Name: 55_27.xml and image_id 111\n",
      "File Name: 15_310.xml and image_id 112\n",
      "File Name: 62_177.xml and image_id 113\n",
      "File Name: cTDaR_t10338.xml and image_id 114\n",
      "File Name: 31_78.xml and image_id 115\n",
      "File Name: 94_112.xml and image_id 116\n",
      "File Name: 21_107.xml and image_id 117\n",
      "File Name: 5661_024.xml and image_id 118\n",
      "File Name: 1675_199.xml and image_id 119\n",
      "File Name: 9534_001.xml and image_id 120\n",
      "File Name: 12_271.xml and image_id 121\n",
      "File Name: 10.1.1.8.2147_15.xml and image_id 122\n",
      "File Name: 27_274.xml and image_id 123\n",
      "File Name: 1589_015.xml and image_id 124\n",
      "File Name: cTDaR_t10085.xml and image_id 125\n",
      "File Name: cTDaR_t10438.xml and image_id 126\n",
      "File Name: cTDaR_t10219.xml and image_id 127\n",
      "File Name: cTDaR_t10526.xml and image_id 128\n",
      "File Name: 76_262.xml and image_id 129\n",
      "File Name: 96_128.xml and image_id 130\n",
      "File Name: 10.1.1.1.2067_4.xml and image_id 131\n",
      "File Name: 13_86.xml and image_id 132\n",
      "File Name: cTDaR_t10159.xml and image_id 133\n",
      "File Name: cTDaR_t10585.xml and image_id 134\n",
      "File Name: 10.1.1.6.2367_46.xml and image_id 135\n",
      "File Name: cTDaR_t10241.xml and image_id 136\n",
      "File Name: 81_178.xml and image_id 137\n",
      "File Name: cTDaR_t10347.xml and image_id 138\n",
      "File Name: 10.1.1.190.2746_10.xml and image_id 139\n",
      "File Name: 9553_023.xml and image_id 140\n",
      "File Name: cTDaR_t10505.xml and image_id 141\n",
      "File Name: 2_61.xml and image_id 142\n",
      "File Name: 89_239.xml and image_id 143\n",
      "File Name: 10.1.1.7.2108_18.xml and image_id 144\n",
      "File Name: cTDaR_t10293.xml and image_id 145\n",
      "File Name: 10.1.1.48.1004_6.xml and image_id 146\n",
      "File Name: 29_39.xml and image_id 147\n",
      "File Name: cTDaR_t10110.xml and image_id 148\n",
      "File Name: 10.1.1.6.2215_30.xml and image_id 149\n",
      "File Name: 10.1.1.120.1632_3.xml and image_id 150\n",
      "File Name: 63_59.xml and image_id 151\n",
      "File Name: cTDaR_t10538.xml and image_id 152\n",
      "File Name: 15_129.xml and image_id 153\n",
      "File Name: cTDaR_t10059.xml and image_id 154\n",
      "File Name: cTDaR_t10055.xml and image_id 155\n",
      "File Name: 10.1.1.160.681_5.xml and image_id 156\n",
      "File Name: 10.1.1.1.2071_7.xml and image_id 157\n",
      "File Name: 8_58.xml and image_id 158\n",
      "File Name: 9_110.xml and image_id 159\n",
      "File Name: 10.1.1.6.2355_3.xml and image_id 160\n",
      "File Name: 10.1.1.6.2208_7.xml and image_id 161\n",
      "File Name: 10.1.1.1.2042_4.xml and image_id 162\n",
      "File Name: 6294_166.xml and image_id 163\n",
      "File Name: cTDaR_t10576.xml and image_id 164\n",
      "File Name: cTDaR_t10447.xml and image_id 165\n",
      "File Name: 62_108.xml and image_id 166\n",
      "File Name: 6580_125.xml and image_id 167\n",
      "File Name: 10.1.1.1.2018_8.xml and image_id 168\n",
      "File Name: cTDaR_t10524.xml and image_id 169\n",
      "File Name: 38_323.xml and image_id 170\n",
      "File Name: 10.1.1.160.617_7.xml and image_id 171\n",
      "File Name: 10.1.1.36.5934_13.xml and image_id 172\n",
      "File Name: cTDaR_t10092.xml and image_id 173\n",
      "File Name: cTDaR_t10116.xml and image_id 174\n",
      "File Name: 10.1.1.7.2119_23.xml and image_id 175\n",
      "File Name: 6575_007.xml and image_id 176\n",
      "File: 6575_007.xml doesn't have any object\n",
      "File Name: 47_120.xml and image_id 177\n",
      "File Name: cTDaR_t10158.xml and image_id 178\n",
      "File Name: cTDaR_t10112.xml and image_id 179\n",
      "File Name: 10.1.1.193.1807_7.xml and image_id 180\n",
      "File Name: 10.1.1.6.2340_6.xml and image_id 181\n",
      "File Name: 18_128.xml and image_id 182\n",
      "File Name: 10.1.1.6.2374_6.xml and image_id 183\n",
      "File Name: cTDaR_t10200.xml and image_id 184\n",
      "File Name: cTDaR_t10304.xml and image_id 185\n",
      "File Name: 91_124.xml and image_id 186\n",
      "File Name: 5435_166.xml and image_id 187\n",
      "File Name: cTDaR_t10414.xml and image_id 188\n",
      "File Name: 96_101.xml and image_id 189\n",
      "File Name: 10.1.1.7.2164_21.xml and image_id 190\n",
      "File Name: 0651_008.xml and image_id 191\n",
      "File Name: 10.1.1.100.308_18.xml and image_id 192\n",
      "File Name: 10.1.1.160.563_8.xml and image_id 193\n",
      "File Name: 0147_125.xml and image_id 194\n",
      "File Name: 10.1.1.1.2145_15.xml and image_id 195\n",
      "File Name: cTDaR_t10586.xml and image_id 196\n",
      "File Name: cTDaR_t10475.xml and image_id 197\n",
      "File Name: 7_204.xml and image_id 198\n",
      "File Name: 60_37.xml and image_id 199\n",
      "File Name: cTDaR_t10561.xml and image_id 200\n",
      "File Name: 9563_104.xml and image_id 201\n",
      "File Name: 21_55.xml and image_id 202\n",
      "File Name: 10.1.1.1.2129_6.xml and image_id 203\n",
      "File Name: cTDaR_t10592.xml and image_id 204\n",
      "File Name: 10.1.1.190.2745_27.xml and image_id 205\n",
      "File Name: 10.1.1.160.503_5.xml and image_id 206\n",
      "File Name: 1238_006.xml and image_id 207\n",
      "File Name: 37_35.xml and image_id 208\n",
      "File Name: cTDaR_t10312.xml and image_id 209\n",
      "File Name: 10.1.1.160.563_6.xml and image_id 210\n",
      "File Name: 10.1.1.8.2180_3.xml and image_id 211\n",
      "File Name: cTDaR_t10068.xml and image_id 212\n",
      "File Name: 27_82.xml and image_id 213\n",
      "File Name: cTDaR_t10195.xml and image_id 214\n",
      "File Name: 9533_039.xml and image_id 215\n",
      "File Name: cTDaR_t10033.xml and image_id 216\n",
      "File Name: 14_106.xml and image_id 217\n",
      "File Name: 44_94.xml and image_id 218\n",
      "File Name: 77_11.xml and image_id 219\n",
      "File Name: 52_28.xml and image_id 220\n",
      "File Name: 10.1.1.34.330_9.xml and image_id 221\n",
      "File Name: cTDaR_t10416.xml and image_id 222\n",
      "File Name: cTDaR_t10341.xml and image_id 223\n",
      "File Name: 81_188.xml and image_id 224\n",
      "File Name: cTDaR_t10237.xml and image_id 225\n",
      "File Name: 5935_149.xml and image_id 226\n",
      "File Name: 1445_046.xml and image_id 227\n",
      "File Name: 5830_158.xml and image_id 228\n",
      "File Name: 5001_025.xml and image_id 229\n",
      "File Name: 9555_015.xml and image_id 230\n",
      "File Name: 10.1.1.35.9666_3.xml and image_id 231\n",
      "File Name: cTDaR_t10392.xml and image_id 232\n",
      "File Name: 87_47.xml and image_id 233\n",
      "File Name: 21_195.xml and image_id 234\n",
      "File Name: 9521_052.xml and image_id 235\n",
      "File Name: 1901_029.xml and image_id 236\n",
      "File Name: 10.1.1.1.2067_10.xml and image_id 237\n",
      "File Name: cTDaR_t10111.xml and image_id 238\n",
      "File Name: 10.1.1.6.2318_8.xml and image_id 239\n",
      "File Name: 9566_032.xml and image_id 240\n",
      "File Name: 10.1.1.8.2121_4.xml and image_id 241\n",
      "File Name: 6294_118.xml and image_id 242\n",
      "File Name: cTDaR_t10256.xml and image_id 243\n",
      "File Name: 10.1.1.160.596_4.xml and image_id 244\n",
      "File Name: 6_236.xml and image_id 245\n",
      "File Name: 43_86.xml and image_id 246\n",
      "File Name: cTDaR_t10562.xml and image_id 247\n",
      "File Name: 10.1.1.160.559_28.xml and image_id 248\n",
      "File Name: 60_104.xml and image_id 249\n",
      "File Name: 1901_014.xml and image_id 250\n",
      "File Name: 10.1.1.185.1552_16.xml and image_id 251\n",
      "File Name: 10.1.1.40.3122_2.xml and image_id 252\n",
      "File Name: 9560_036.xml and image_id 253\n",
      "File Name: cTDaR_t10513.xml and image_id 254\n",
      "File Name: cTDaR_t10437.xml and image_id 255\n",
      "File Name: cTDaR_t10542.xml and image_id 256\n",
      "File Name: 10.1.1.6.2190_5.xml and image_id 257\n",
      "File Name: 10.1.1.1.2019_2.xml and image_id 258\n",
      "File Name: 15_141.xml and image_id 259\n",
      "File Name: cTDaR_t10232.xml and image_id 260\n",
      "File Name: 2_100.xml and image_id 261\n",
      "File Name: cTDaR_t10027.xml and image_id 262\n",
      "File Name: 10.1.1.1.2063_21.xml and image_id 263\n",
      "File Name: 5992_072.xml and image_id 264\n",
      "File Name: cTDaR_t10090.xml and image_id 265\n",
      "File Name: cTDaR_t10451.xml and image_id 266\n",
      "File Name: 81_86.xml and image_id 267\n",
      "File Name: 44_115.xml and image_id 268\n",
      "File Name: 45_57.xml and image_id 269\n",
      "File Name: 5921_071.xml and image_id 270\n",
      "File Name: 10.1.1.6.2272_17.xml and image_id 271\n",
      "File Name: 18_61.xml and image_id 272\n",
      "File Name: 9549_030.xml and image_id 273\n",
      "File Name: cTDaR_t10194.xml and image_id 274\n",
      "File Name: cTDaR_t10446.xml and image_id 275\n",
      "File Name: 10.1.1.120.1603_23.xml and image_id 276\n",
      "File Name: 10.1.1.160.604_33.xml and image_id 277\n",
      "File Name: 48_80.xml and image_id 278\n",
      "File Name: 14_16.xml and image_id 279\n",
      "File Name: 10.1.1.160.669_11.xml and image_id 280\n",
      "File Name: 10.1.1.160.684_3.xml and image_id 281\n",
      "File Name: 10.1.1.1.2032_6.xml and image_id 282\n",
      "File Name: 10.1.1.170.1002_23.xml and image_id 283\n",
      "File Name: 9520_037.xml and image_id 284\n",
      "File Name: 93_167.xml and image_id 285\n",
      "File Name: 10.1.1.180.564_70.xml and image_id 286\n",
      "File Name: cTDaR_t10514.xml and image_id 287\n",
      "File Name: 1550_007.xml and image_id 288\n",
      "File Name: cTDaR_t10337.xml and image_id 289\n",
      "File Name: 9549_023.xml and image_id 290\n",
      "File Name: cTDaR_t10303.xml and image_id 291\n",
      "File Name: 86_246.xml and image_id 292\n",
      "File Name: cTDaR_t10454.xml and image_id 293\n",
      "File Name: 30_291.xml and image_id 294\n",
      "File Name: cTDaR_t10154.xml and image_id 295\n",
      "File Name: cTDaR_t10388.xml and image_id 296\n",
      "File Name: 1339_086.xml and image_id 297\n",
      "File Name: cTDaR_t10580.xml and image_id 298\n",
      "File Name: cTDaR_t10056.xml and image_id 299\n",
      "File Name: 21_71.xml and image_id 300\n",
      "File Name: cTDaR_t10107.xml and image_id 301\n",
      "File Name: 94_56.xml and image_id 302\n",
      "File Name: 25_62.xml and image_id 303\n",
      "File Name: 13_65.xml and image_id 304\n",
      "File Name: cTDaR_t10037.xml and image_id 305\n",
      "File Name: cTDaR_t10355.xml and image_id 306\n",
      "File Name: cTDaR_t10257.xml and image_id 307\n",
      "File Name: cTDaR_t10405.xml and image_id 308\n",
      "File Name: cTDaR_t10141.xml and image_id 309\n",
      "File Name: cTDaR_t10015.xml and image_id 310\n",
      "File Name: 10.1.1.1.2032_10.xml and image_id 311\n",
      "File Name: cTDaR_t10493.xml and image_id 312\n",
      "File Name: 9503_027.xml and image_id 313\n",
      "File Name: 1674_088.xml and image_id 314\n",
      "File Name: 65_2.xml and image_id 315\n",
      "File Name: cTDaR_t10546.xml and image_id 316\n",
      "File Name: cTDaR_t10044.xml and image_id 317\n",
      "File Name: cTDaR_t10435.xml and image_id 318\n",
      "File Name: 10.1.1.37.368_2.xml and image_id 319\n",
      "File Name: 5611_013.xml and image_id 320\n",
      "File Name: 10.1.1.120.1614_4.xml and image_id 321\n",
      "File Name: cTDaR_t10396.xml and image_id 322\n",
      "File Name: cTDaR_t10243.xml and image_id 323\n",
      "File Name: 10.1.1.7.2148_31.xml and image_id 324\n",
      "File Name: 8_165.xml and image_id 325\n",
      "File Name: 10.1.1.160.531_12.xml and image_id 326\n",
      "File Name: 5095_019.xml and image_id 327\n",
      "File Name: cTDaR_t10067.xml and image_id 328\n",
      "File Name: cTDaR_t10230.xml and image_id 329\n",
      "File Name: 5366_142.xml and image_id 330\n",
      "File Name: 10.1.1.160.557_3.xml and image_id 331\n",
      "File Name: 45_23.xml and image_id 332\n",
      "File Name: 82_238.xml and image_id 333\n",
      "File Name: 10.1.1.8.2185_13.xml and image_id 334\n",
      "File Name: cTDaR_t10206.xml and image_id 335\n",
      "File Name: 9557_020.xml and image_id 336\n",
      "File Name: 6294_160.xml and image_id 337\n",
      "File Name: 1343_073.xml and image_id 338\n",
      "File Name: cTDaR_t10266.xml and image_id 339\n",
      "File Name: 91_204.xml and image_id 340\n",
      "File Name: 73_49.xml and image_id 341\n",
      "File Name: 55_106.xml and image_id 342\n",
      "File Name: 18_130.xml and image_id 343\n",
      "File Name: 38_102.xml and image_id 344\n",
      "File Name: 1723_194.xml and image_id 345\n",
      "File Name: 10.1.1.6.2264_54.xml and image_id 346\n",
      "File Name: 10.1.1.160.630_12.xml and image_id 347\n",
      "File Name: cTDaR_t10253.xml and image_id 348\n",
      "File Name: cTDaR_t10102.xml and image_id 349\n",
      "File Name: 42_78.xml and image_id 350\n",
      "File Name: 9516_041.xml and image_id 351\n",
      "File Name: 5622_013.xml and image_id 352\n",
      "File Name: 10.1.1.179.3009_11.xml and image_id 353\n",
      "File Name: cTDaR_t10443.xml and image_id 354\n",
      "File Name: 77_78.xml and image_id 355\n",
      "File Name: cTDaR_t10011.xml and image_id 356\n",
      "File Name: 9563_061.xml and image_id 357\n",
      "File Name: cTDaR_t10517.xml and image_id 358\n",
      "File Name: 5830_191.xml and image_id 359\n",
      "File Name: 1384_097.xml and image_id 360\n",
      "File Name: 5926_018.xml and image_id 361\n",
      "File Name: 1539_012.xml and image_id 362\n",
      "File Name: 38_176.xml and image_id 363\n",
      "File Name: 5252_009.xml and image_id 364\n",
      "File Name: 55_300.xml and image_id 365\n",
      "File Name: 10.1.1.160.651_12.xml and image_id 366\n",
      "File Name: 10.1.1.160.660_6.xml and image_id 367\n",
      "File Name: 31_178.xml and image_id 368\n",
      "File Name: 60_296.xml and image_id 369\n",
      "File Name: cTDaR_t10072.xml and image_id 370\n",
      "File Name: 91_44.xml and image_id 371\n",
      "File Name: 10.1.1.160.624_15.xml and image_id 372\n",
      "File Name: cTDaR_t10178.xml and image_id 373\n",
      "File Name: 6347_112.xml and image_id 374\n",
      "File Name: 48_112.xml and image_id 375\n",
      "File Name: 89_38.xml and image_id 376\n",
      "File Name: cTDaR_t10017.xml and image_id 377\n",
      "File Name: cTDaR_t10361.xml and image_id 378\n",
      "File Name: 4_301.xml and image_id 379\n",
      "File Name: cTDaR_t10537.xml and image_id 380\n",
      "File Name: 9_81.xml and image_id 381\n",
      "File Name: 10.1.1.120.1527_3.xml and image_id 382\n",
      "File Name: cTDaR_t10470.xml and image_id 383\n",
      "File Name: cTDaR_t10098.xml and image_id 384\n",
      "File Name: 80_286.xml and image_id 385\n",
      "File Name: 8_224.xml and image_id 386\n",
      "File Name: 48_65.xml and image_id 387\n",
      "File Name: 1_57.xml and image_id 388\n",
      "File Name: 10.1.1.8.2124_7.xml and image_id 389\n",
      "File Name: 34_206.xml and image_id 390\n",
      "File Name: cTDaR_t10316.xml and image_id 391\n",
      "File Name: cTDaR_t10511.xml and image_id 392\n",
      "File Name: 10.1.1.6.2277_10.xml and image_id 393\n",
      "File Name: cTDaR_t10400.xml and image_id 394\n",
      "File Name: 2029_489.xml and image_id 395\n",
      "File Name: 57_78.xml and image_id 396\n",
      "File Name: 10.1.1.6.2260_4.xml and image_id 397\n",
      "File Name: 10.1.1.120.1619_11.xml and image_id 398\n",
      "File Name: cTDaR_t10531.xml and image_id 399\n",
      "File Name: 1676_008.xml and image_id 400\n",
      "File Name: 10.1.1.8.2160_5.xml and image_id 401\n",
      "File Name: 10.1.1.55.1001_15.xml and image_id 402\n",
      "File Name: 10.1.1.7.2123_2.xml and image_id 403\n",
      "File Name: cTDaR_t10491.xml and image_id 404\n",
      "File Name: 94_44.xml and image_id 405\n",
      "File Name: 45_42.xml and image_id 406\n",
      "File Name: cTDaR_t10113.xml and image_id 407\n",
      "File Name: 23_56.xml and image_id 408\n",
      "File Name: 2_57.xml and image_id 409\n",
      "File Name: cTDaR_t10504.xml and image_id 410\n",
      "File Name: 10.1.1.6.2243_7.xml and image_id 411\n",
      "File Name: 10.1.1.32.4629_8.xml and image_id 412\n",
      "File Name: 10.1.1.186.1550_6.xml and image_id 413\n",
      "File Name: 1813_081.xml and image_id 414\n",
      "File Name: 10.1.1.120.1504_11.xml and image_id 415\n",
      "File Name: 9503_031.xml and image_id 416\n",
      "File Name: 10.1.1.160.690_35.xml and image_id 417\n",
      "File Name: 40_21.xml and image_id 418\n",
      "File Name: cTDaR_t10331.xml and image_id 419\n",
      "File Name: 0146_281.xml and image_id 420\n",
      "File Name: 1723_250.xml and image_id 421\n",
      "File Name: 5417_044.xml and image_id 422\n",
      "File Name: 10.1.1.160.507_10.xml and image_id 423\n",
      "File Name: cTDaR_t10473.xml and image_id 424\n",
      "File Name: 10.1.1.34.7043_72.xml and image_id 425\n",
      "File Name: cTDaR_t10054.xml and image_id 426\n",
      "File Name: cTDaR_t10394.xml and image_id 427\n",
      "File Name: cTDaR_t10525.xml and image_id 428\n",
      "File Name: 10.1.1.160.500_5.xml and image_id 429\n",
      "File Name: 0203_207.xml and image_id 430\n",
      "File Name: cTDaR_t10176.xml and image_id 431\n",
      "File Name: 10.1.1.177.3001_114.xml and image_id 432\n",
      "File Name: 1384_058.xml and image_id 433\n",
      "File Name: cTDaR_t10126.xml and image_id 434\n",
      "File Name: 10.1.1.1.2091_6.xml and image_id 435\n",
      "File Name: cTDaR_t10317.xml and image_id 436\n",
      "File Name: 5856_026.xml and image_id 437\n",
      "File Name: cTDaR_t10221.xml and image_id 438\n",
      "File Name: 10.1.1.190.2741_20.xml and image_id 439\n",
      "File Name: 1295_064.xml and image_id 440\n",
      "File Name: cTDaR_t10440.xml and image_id 441\n",
      "File Name: cTDaR_t10198.xml and image_id 442\n",
      "File Name: cTDaR_t10477.xml and image_id 443\n",
      "File Name: 10.1.1.176.3008_3.xml and image_id 444\n",
      "File Name: 1674_138.xml and image_id 445\n",
      "File Name: 10.1.1.160.517_4.xml and image_id 446\n",
      "File Name: 9568_033.xml and image_id 447\n",
      "File Name: 20_72.xml and image_id 448\n",
      "File Name: 5195_077.xml and image_id 449\n",
      "File Name: cTDaR_t10441.xml and image_id 450\n",
      "File Name: 38_185.xml and image_id 451\n",
      "File Name: 10.1.1.160.611_59.xml and image_id 452\n",
      "File Name: 60_100.xml and image_id 453\n",
      "File Name: cTDaR_t10382.xml and image_id 454\n",
      "File Name: 32_175.xml and image_id 455\n",
      "File Name: cTDaR_t10169.xml and image_id 456\n",
      "File Name: 55_23.xml and image_id 457\n",
      "File Name: 5367_007.xml and image_id 458\n",
      "File Name: 1060_146.xml and image_id 459\n",
      "File Name: 10.1.1.1.2031_24.xml and image_id 460\n",
      "File Name: 10.1.1.185.1562_88.xml and image_id 461\n",
      "File Name: 73_202.xml and image_id 462\n",
      "File Name: cTDaR_t10391.xml and image_id 463\n",
      "File Name: 2117_329.xml and image_id 464\n",
      "File Name: cTDaR_t10215.xml and image_id 465\n",
      "File Name: cTDaR_t10170.xml and image_id 466\n",
      "File Name: 10.1.1.33.5766_4.xml and image_id 467\n",
      "File Name: cTDaR_t10387.xml and image_id 468\n",
      "File Name: 6504_018.xml and image_id 469\n",
      "File Name: 10.1.1.1.2097_4.xml and image_id 470\n",
      "File Name: cTDaR_t10079.xml and image_id 471\n",
      "File Name: 10.1.1.20.2150_4.xml and image_id 472\n",
      "File Name: 92_27.xml and image_id 473\n",
      "File Name: cTDaR_t10148.xml and image_id 474\n",
      "File Name: cTDaR_t10228.xml and image_id 475\n",
      "File Name: 10.1.1.120.1505_45.xml and image_id 476\n",
      "File Name: 10.1.1.193.1816_4.xml and image_id 477\n",
      "File Name: cTDaR_t10413.xml and image_id 478\n",
      "File Name: 0101_003.xml and image_id 479\n",
      "File Name: 5842_099.xml and image_id 480\n",
      "File Name: cTDaR_t10558.xml and image_id 481\n",
      "File Name: 10.1.1.120.1527_4.xml and image_id 482\n",
      "File Name: 91_92.xml and image_id 483\n",
      "File Name: 10.1.1.7.2112_16.xml and image_id 484\n",
      "File Name: 10.1.1.1.2013_64.xml and image_id 485\n",
      "File Name: cTDaR_t10005.xml and image_id 486\n",
      "File Name: 31_143.xml and image_id 487\n",
      "File Name: 58_204.xml and image_id 488\n",
      "File Name: 63_51.xml and image_id 489\n",
      "File Name: 80_80.xml and image_id 490\n",
      "File Name: cTDaR_t10171.xml and image_id 491\n",
      "File Name: 5008_029.xml and image_id 492\n",
      "File Name: 10.1.1.1.2051_5.xml and image_id 493\n",
      "File Name: 10.1.1.6.2216_5.xml and image_id 494\n",
      "File Name: cTDaR_t10329.xml and image_id 495\n",
      "File Name: cTDaR_t10310.xml and image_id 496\n",
      "File Name: 44_30.xml and image_id 497\n",
      "File Name: 5685_032.xml and image_id 498\n",
      "File Name: 10.1.1.6.2327_7.xml and image_id 499\n",
      "File Name: 10.1.1.1.2139_58.xml and image_id 500\n",
      "File Name: cTDaR_t10128.xml and image_id 501\n",
      "File Name: 10.1.1.160.623_8.xml and image_id 502\n",
      "File Name: 43_100.xml and image_id 503\n",
      "File Name: 49_51.xml and image_id 504\n",
      "File Name: cTDaR_t10548.xml and image_id 505\n",
      "File Name: 31_132.xml and image_id 506\n",
      "File Name: 10.1.1.1.2111_6.xml and image_id 507\n",
      "File Name: cTDaR_t10135.xml and image_id 508\n",
      "File Name: 9511_031.xml and image_id 509\n",
      "File Name: cTDaR_t10238.xml and image_id 510\n",
      "File Name: cTDaR_t10490.xml and image_id 511\n",
      "File Name: 10.1.1.6.2372_3.xml and image_id 512\n",
      "File Name: 76_265.xml and image_id 513\n",
      "File Name: cTDaR_t10094.xml and image_id 514\n",
      "File Name: cTDaR_t10078.xml and image_id 515\n",
      "File Name: 8_73.xml and image_id 516\n",
      "File Name: 10.1.1.185.1560_10.xml and image_id 517\n",
      "File Name: 0651_013.xml and image_id 518\n",
      "File Name: cTDaR_t10097.xml and image_id 519\n",
      "File Name: 10.1.1.6.2381_5.xml and image_id 520\n",
      "File Name: cTDaR_t10267.xml and image_id 521\n",
      "File Name: 5248_035.xml and image_id 522\n",
      "File Name: cTDaR_t10553.xml and image_id 523\n",
      "File Name: 10.1.1.1.2019_3.xml and image_id 524\n",
      "File Name: cTDaR_t10093.xml and image_id 525\n",
      "File Name: 6578_052.xml and image_id 526\n",
      "File Name: 10.1.1.177.3004_6.xml and image_id 527\n",
      "File Name: 6294_128.xml and image_id 528\n",
      "File Name: cTDaR_t10510.xml and image_id 529\n",
      "File Name: 9501_032.xml and image_id 530\n",
      "File Name: cTDaR_t10030.xml and image_id 531\n",
      "File Name: cTDaR_t10281.xml and image_id 532\n",
      "File Name: cTDaR_t10555.xml and image_id 533\n",
      "File Name: cTDaR_t10103.xml and image_id 534\n",
      "File Name: cTDaR_t10201.xml and image_id 535\n",
      "File Name: 10.1.1.193.1803_3.xml and image_id 536\n",
      "File Name: 92_227.xml and image_id 537\n",
      "File Name: 5244_103.xml and image_id 538\n",
      "File Name: cTDaR_t10587.xml and image_id 539\n",
      "File Name: cTDaR_t10028.xml and image_id 540\n",
      "File Name: cTDaR_t10167.xml and image_id 541\n",
      "File Name: 5592_012.xml and image_id 542\n",
      "File Name: 10.1.1.1.2055_4.xml and image_id 543\n",
      "File Name: 33_17.xml and image_id 544\n",
      "File Name: 14_41.xml and image_id 545\n",
      "File Name: 46_25.xml and image_id 546\n",
      "File Name: 10.1.1.193.1812_21.xml and image_id 547\n",
      "File Name: 1551_123.xml and image_id 548\n",
      "File Name: 10.1.1.1.2042_6.xml and image_id 549\n",
      "File Name: 10.1.1.120.1504_6.xml and image_id 550\n",
      "File Name: 9510_037.xml and image_id 551\n",
      "File Name: cTDaR_t10014.xml and image_id 552\n",
      "File Name: 5649_040.xml and image_id 553\n",
      "File Name: 13_138.xml and image_id 554\n",
      "File Name: 10.1.1.160.546_36.xml and image_id 555\n",
      "File Name: 9557_035.xml and image_id 556\n",
      "File Name: 56_122.xml and image_id 557\n",
      "File Name: 10.1.1.120.1525_53.xml and image_id 558\n",
      "File Name: 29_62.xml and image_id 559\n",
      "File Name: 46_73.xml and image_id 560\n",
      "File Name: 53_133.xml and image_id 561\n",
      "File Name: 30_20.xml and image_id 562\n",
      "File Name: 10.1.1.37.4664_23.xml and image_id 563\n",
      "File Name: 10.1.1.6.2264_70.xml and image_id 564\n",
      "File Name: 10.1.1.30.3555_10.xml and image_id 565\n",
      "File Name: cTDaR_t10292.xml and image_id 566\n",
      "File Name: 31_44.xml and image_id 567\n",
      "File Name: 8_230.xml and image_id 568\n",
      "File Name: 10.1.1.160.604_22.xml and image_id 569\n",
      "File Name: 35_66.xml and image_id 570\n",
      "File Name: 14_65.xml and image_id 571\n",
      "File Name: 6580_018.xml and image_id 572\n",
      "File Name: 39_106.xml and image_id 573\n",
      "File Name: 5814_092.xml and image_id 574\n",
      "File Name: 10.1.1.6.2284_7.xml and image_id 575\n",
      "File Name: 43_309.xml and image_id 576\n",
      "File Name: cTDaR_t10280.xml and image_id 577\n",
      "File Name: 1412_006.xml and image_id 578\n",
      "File Name: cTDaR_t10395.xml and image_id 579\n",
      "File Name: cTDaR_t10494.xml and image_id 580\n",
      "File Name: cTDaR_t10393.xml and image_id 581\n",
      "581\n",
      "Bordered :  844  Cell :  0  Bless :  0\n",
      "844\n"
     ]
    }
   ],
   "source": [
    "## Script for Converting Pascal VOC annotations to Coco Json format\n",
    "## This script shows and example conversion of our table dataset pascal voc\n",
    "## annotations conversion to coco annotations  \n",
    "\n",
    "## Usage :\n",
    "# You need to first create a txt file containing names of all pascal voc files\n",
    "# You can use following linux command\n",
    "# ls -1 | sed -e 's/\\.xml$//' | sort -n > \"/path/to/folder/coco.txt\"\n",
    "# And then read the comments in this script to understand its working\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import xmltodict\n",
    "import json\n",
    "from xml.dom import minidom\n",
    "from collections import OrderedDict\n",
    "\n",
    "def generateVOC2Json(rootDir,xmlFiles):\n",
    "  attrDict = dict()\n",
    "  # Add categories according to you Pascal VOC annotations\n",
    "  attrDict[\"categories\"]=[{\"supercategory\":\"none\",\"id\":1,\"name\":\"Table\"}]\n",
    "  images = list()\n",
    "  annotations = list()\n",
    "  id1 = 1\n",
    "\n",
    "  # Some random variables\n",
    "  cnt_bor = 0\n",
    "  cnt_cell = 0\n",
    "  cnt_bless = 0\n",
    "\n",
    "  # Main execution loop\n",
    "  for root, dirs, files in os.walk(rootDir):\n",
    "    image_id = 0\n",
    "    for file in xmlFiles:\n",
    "      image_id = image_id + 1\n",
    "      if file in files:\n",
    "        annotation_path = os.path.abspath(os.path.join(root, file))\n",
    "        image = dict()\n",
    "        doc = xmltodict.parse(open(annotation_path).read())\n",
    "        image['file_name'] = str(doc['annotation']['filename'])\n",
    "        image['height'] = int(doc['annotation']['size']['height'])\n",
    "        image['width'] = int(doc['annotation']['size']['width'])\n",
    "        image['id'] = image_id\n",
    "        print(\"File Name: {} and image_id {}\".format(file, image_id))\n",
    "        images.append(image)\n",
    "        if 'object' in doc['annotation']:\n",
    "          for key,vals in doc['annotation'].items():\n",
    "            if(key=='object'):\n",
    "              for value in attrDict[\"categories\"]:\n",
    "                if(not isinstance(vals, list)):\n",
    "                  vals = [vals]\n",
    "                for val in vals:\n",
    "                  if str(val['name']).lower() == str(value[\"name\"]).lower():\n",
    "                    annotation = dict()\n",
    "                    annotation[\"iscrowd\"] = 0\n",
    "                    annotation[\"image_id\"] = image_id\n",
    "                    x1 = int(val[\"bndbox\"][\"xmin\"])  - 1\n",
    "                    y1 = int(val[\"bndbox\"][\"ymin\"]) - 1\n",
    "                    x2 = int(val[\"bndbox\"][\"xmax\"]) - x1\n",
    "                    y2 = int(val[\"bndbox\"][\"ymax\"]) - y1\n",
    "                    annotation[\"bbox\"] = [x1, y1, x2, y2]\n",
    "                    annotation[\"area\"] = float(x2 * y2)\n",
    "                    annotation[\"category_id\"] = value[\"id\"]\n",
    "\n",
    "                    # Tracking the count\n",
    "                    if(value[\"id\"] == 1):\n",
    "                      cnt_bor += 1\n",
    "                    if(value[\"id\"] == 2):\n",
    "                      cnt_cell += 1\n",
    "                    if(value[\"id\"] == 3):\n",
    "                      cnt_bless += 1\n",
    "\n",
    "                    annotation[\"ignore\"] = 0\n",
    "                    annotation[\"id\"] = id1\n",
    "                    annotation[\"segmentation\"] = [[x1,y1,x1,(y1 + y2), (x1 + x2), (y1 + y2), (x1 + x2), y1]]\n",
    "                    id1 +=1\n",
    "                    annotations.append(annotation)\n",
    "        else:\n",
    "          print(\"File: {} doesn't have any object\".format(file))\n",
    "      else:\n",
    "        print(\"File: {} not found\".format(file))\n",
    "\n",
    "  attrDict[\"images\"] = images\t\n",
    "  attrDict[\"annotations\"] = annotations\n",
    "  attrDict[\"type\"] = \"instances\"\n",
    "\n",
    "  # Printing out some statistics\n",
    "  print(len(images))\n",
    "  print(\"Bordered : \",cnt_bor,\" Cell : \",cnt_cell,\" Bless : \",cnt_bless)\n",
    "  print(len(annotations))\n",
    "\n",
    "  # Save the final JSON file\n",
    "  # jsonString = json.dumps(attrDict)\n",
    "  jsonString = json.dumps(attrDict, indent = 4, sort_keys=True)\n",
    "  with open(\"train.json\", \"w\") as f:\n",
    "    f.write(jsonString)\n",
    "\n",
    "# Path to the pascal voc xml files \n",
    "rootDir = \"/scratch/m23csa016/tabdet_data/Orig_Annotations\"\n",
    "\n",
    "# Start execution\n",
    "generateVOC2Json(rootDir, train_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
